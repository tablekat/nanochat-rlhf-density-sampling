# Complete File Inventory: speedrun.sh vs kat_speedrun.sh

This document lists **every single file** that gets created, downloaded, or generated by running either script.

---

## TL;DR - Disk Space Requirements

| Script            | Total Size | Description                     |
| ----------------- | ---------- | ------------------------------- |
| `speedrun.sh`     | ~30-50 GB  | Pretraining + tokenizer + SFT   |
| `kat_speedrun.sh` | ~35-55 GB  | Everything above PLUS GRPO + RM |

---

## FLAT FILE LIST (Full Paths)

### speedrun.sh Creates:

```
.venv/bin/python                              # Python executable
.venv/lib/python3.*/site-packages/torch/*     # PyTorch library
.venv/lib/python3.*/site-packages/pytest/*    # Test framework
.venv/pyvenv.cfg                              # venv config
rustbpe/target/release/deps/*                 # Compiled Rust binary
rustbpe/target/release/build/*                # Build artifacts
$HOME/.cache/nanochat/data_shards/shard_*.bin # Pretraining data (240 files, 100MB each)
$HOME/.cache/nanochat/tok/ckpt.pt            # Tokenizer checkpoint (50MB)
$HOME/.cache/nanochat/tok/vocab.txt          # Vocabulary file
$HOME/.cache/nanochat/tok/tokenizer_config.json # Tokenizer config
$HOME/.cache/nanochat/eval_bundle/CORE/*     # CORE eval dataset
$HOME/.cache/nanochat/eval_bundle/GSM8K/*    # GSM8K dataset
$HOME/.cache/nanochat/eval_bundle/ARC/*      # ARC dataset
$HOME/.cache/nanochat/eval_bundle/MMLU/*     # MMLU dataset
$HOME/.cache/nanochat/identity_conversations.jsonl # Identity data (2.3MB)
outs/base/ckpt.pt                            # Base model (2.5GB)
outs/base/ckpt_*.pt                          # Intermediate checkpoints
outs/base/config.json                        # Model config
outs/base/training_log.txt                   # Training logs
outs/mid/ckpt.pt                             # Mid-trained model (2.5GB)
outs/mid/ckpt_*.pt                           # Intermediate checkpoints
outs/mid/config.json                         # Model config
outs/mid/training_log.txt                    # Training logs
outs/sft/ckpt.pt                             # SFT model (2.5GB)
outs/sft/ckpt_*.pt                           # Intermediate checkpoints
outs/sft/config.json                         # Model config
outs/sft/training_log.txt                    # Training logs
outs/base/logs/events.out.tfevents.*         # TensorBoard base logs
outs/mid/logs/events.out.tfevents.*          # TensorBoard mid logs
outs/sft/logs/events.out.tfevents.*          # TensorBoard sft logs
report.md                                     # Final report
$NANOCHAT_BASE_DIR/report/base_report.md     # Base phase report
$NANOCHAT_BASE_DIR/report/mid_report.md      # Mid phase report
$NANOCHAT_BASE_DIR/report/sft_report.md      # SFT phase report
```

### kat_speedrun.sh ADDITIONALLY Creates:

```
outs/rm/ckpt.pt                              # Reward model (100-200MB)
outs/rm/config.json                          # RM config
outs/rm/logs/events.out.tfevents.*           # TensorBoard RM logs
.cache/data/pairs_all.jsonl                  # All pairs (276k, 500MB)
.cache/data/prompts_all.jsonl                # Unique prompts (89k, 50MB)
.cache/data/prompt_id_map.tsv                # Prompt ID map (50MB)
.cache/data/stats.txt                        # Dataset stats (1KB)
outs/grpo_density/ckpt.pt                    # GRPO density model (2.5GB)
outs/grpo_density/ckpt_*.pt                  # GRPO density checkpoints
outs/grpo_density/config.json                # GRPO density config
outs/grpo_density/training_log.txt           # GRPO density logs
outs/grpo_density/logs/events.out.tfevents.* # TensorBoard density logs
outs/grpo_density/logs/train/loss            # Density loss metrics
outs/grpo_density/logs/train/pref_loss       # Preference loss
outs/grpo_density/logs/train/kl_loss         # KL divergence loss
outs/grpo_density/logs/train/lr              # Learning rate
outs/grpo_baseline/ckpt.pt                   # GRPO baseline model (2.5GB)
outs/grpo_baseline/ckpt_*.pt                 # GRPO baseline checkpoints
outs/grpo_baseline/config.json               # GRPO baseline config
outs/grpo_baseline/training_log.txt          # GRPO baseline logs
outs/grpo_baseline/logs/events.out.tfevents.* # TensorBoard baseline logs
outs/grpo_baseline/logs/train/loss           # Baseline loss metrics
outs/grpo_baseline/logs/train/pref_loss      # Baseline pref loss
outs/grpo_baseline/logs/train/kl_loss        # Baseline KL loss
outs/grpo_baseline/logs/train/lr             # Baseline learning rate
.cache/diversity_report.md                   # Evaluation report (50-100KB)
```

### Temporary/Cache Files (Usually Cleaned):

```
eval_bundle.zip                              # Temp zip file (deleted after unzip)
wandb/                                       # wandb cache directory
__pycache__/                                 # Python cache (recursive)
*.pyc                                        # Compiled Python (recursive)
.pytest_cache/                               # pytest cache
.ruff_cache/                                 # ruff linter cache
```

---

## SECTION 1: Python Environment & Build Tools

### Created by both scripts:

```
.venv/                          # Python virtual environment
├── bin/                        # Executables
├── lib/                        # Python packages
└── pyvenv.cfg                  # venv config
```

**Size**: ~500-800 MB (depends on PyTorch installation)

### Build Artifacts:

```
rustbpe/target/                 # Rust build artifacts (from maturin)
├── release/                    # Compiled binaries
└── (many intermediate files)
```

**Size**: ~1-2 GB

---

## SECTION 2: Data Downloads (Base Directory: `$HOME/.cache/nanochat/`)

### Tokenizer & Pretraining Data:

```
$HOME/.cache/nanochat/
├── data_shards/                # Downloaded pretraining data
│   ├── shard_000000.bin        # (~100 MB each)
│   ├── shard_000001.bin
│   ├── shard_000002.bin
│   ├── ...
│   └── shard_000239.bin        # Up to 240 shards for speedrun.sh
│
├── tok/                        # Tokenizer files
│   ├── ckpt.pt                 # Tokenizer checkpoint (~50 MB)
│   ├── vocab.txt               # Vocabulary file
│   └── tokenizer_config.json   # Configuration
│
├── eval_bundle/                # Downloaded evaluation data
│   ├── CORE/                   # CORE evaluation dataset
│   ├── GSM8K/                  # GSM8K math problems
│   ├── ARC/                    # ARC benchmark
│   ├── MMLU/                   # MMLU benchmark
│   └── (other eval datasets)
│
└── identity_conversations.jsonl # Downloaded (~2.3 MB)
```

**Sizes**:

- Data shards: 240 × 100 MB = **~24 GB** (speedrun.sh only)
- Tokenizer: **~50 MB**
- Eval bundle: **~162 MB**
- Identity conversations: **~2.3 MB**

---

## SECTION 3: Training Checkpoints & Outputs (Root: `outs/`)

### Base Model (Pretraining):

```
outs/base/
├── ckpt.pt                     # Base model checkpoint (561M params)
├── ckpt_*.pt                   # Intermediate checkpoints (if saved)
├── config.json                 # Model configuration
└── training_log.txt            # Training logs
```

**Size**: ~2.5 GB (main checkpoint)

### Mid-Training:

```
outs/mid/
├── ckpt.pt                     # Mid-trained checkpoint
├── ckpt_*.pt                   # Intermediate checkpoints
└── config.json
```

**Size**: ~2.5 GB

### Supervised Fine-Tuning (SFT):

```
outs/sft/
├── ckpt.pt                     # SFT checkpoint
├── ckpt_*.pt                   # Intermediate checkpoints
└── config.json
```

**Size**: ~2.5 GB

### KAT-Specific: Reward Model Training

```
outs/rm/                        # ONLY in kat_speedrun.sh
├── ckpt.pt                     # Reward model checkpoint (head only)
├── logs/                       # TensorBoard logs
│   ├── events.out.tfevents.xxx
│   └── ...
└── config.json
```

**Size**: ~100-200 MB (just the reward head)

### KAT-Specific: GRPO with Density Sampling (Main Experiment)

```
outs/grpo_density/              # ONLY in kat_speedrun.sh
├── ckpt.pt                     # Policy model (561M params)
├── ckpt_*.pt                   # Intermediate checkpoints
├── logs/                       # TensorBoard training logs
│   ├── train/
│   │   ├── loss
│   │   ├── pref_loss
│   │   ├── kl_loss
│   │   └── lr
│   └── events.out.tfevents.xxx
├── config.json                 # Training config
└── training_log.txt
```

**Size**: ~2.5 GB (main checkpoint) + ~500 MB (logs)

### KAT-Specific: GRPO Baseline (Uniform Sampling Control)

```
outs/grpo_baseline/             # ONLY in kat_speedrun.sh
├── ckpt.pt                     # Policy model (561M params)
├── ckpt_*.pt                   # Intermediate checkpoints
├── logs/                       # TensorBoard training logs
├── config.json
└── training_log.txt
```

**Size**: ~2.5 GB (main checkpoint) + ~500 MB (logs)

---

## SECTION 4: Data Processing (KAT-Specific)

```
.cache/data/                    # ONLY in kat_speedrun.sh
├── pairs_all.jsonl             # All preference pairs from 3 datasets
│                               # ~276k pairs, ~500 MB
├── prompts_all.jsonl           # Deduplicated unique prompts
│                               # ~89k prompts, ~50 MB
├── prompt_id_map.tsv           # Prompt ID to text mapping
│                               # ~50 MB
└── stats.txt                   # Dataset statistics
                                # ~1 KB
```

**Total Size**: ~600 MB

---

## SECTION 5: Reports & Logs

### Speedrun.sh Reports:

```
report.md                       # Main report (copied to root)
$NANOCHAT_BASE_DIR/report/
├── base_report.md              # Base pretraining report
├── mid_report.md               # Mid-training report
├── sft_report.md               # SFT report
└── combined_report.md          # All metrics combined
```

**Size**: ~100-500 KB

### KAT-Specific: Evaluation Report

```
.cache/diversity_report.md      # ONLY in kat_speedrun.sh
                                # Comprehensive evaluation of both models
                                # Includes em-dash analysis, Gini coefficients, etc.
                                # ~50-100 KB
```

---

## SECTION 6: TensorBoard Logs (Training Metrics)

Created during training runs:

```
outs/base/logs/events.out.tfevents.xxx
outs/mid/logs/events.out.tfevents.xxx
outs/sft/logs/events.out.tfevents.xxx
outs/rm/logs/events.out.tfevents.xxx          # KAT only
outs/grpo_density/logs/events.out.tfevents.xxx    # KAT only
outs/grpo_baseline/logs/events.out.tfevents.xxx   # KAT only
```

**Size**: ~100-200 MB each (depends on logging frequency)

---

## SECTION 7: Temporary Files (May Be Deleted)

During runtime, these temporary files are created and usually cleaned up:

```
eval_bundle.zip                 # Temporary (deleted after unzip)
eval_bundle/                    # Temporary during unzip
wandb/                          # wandb runtime cache (if using wandb)
__pycache__/                    # Python bytecode
*.pyc                           # Compiled Python files
.pytest_cache/                  # pytest cache
```

**Size**: ~100-500 MB (temporary, usually cleaned)

---

## SECTION 8: Complete File Tree

### speedrun.sh ONLY creates:

```
Home directory:
  .cache/
    nanochat/
      data_shards/              (8-240 shards, 800MB - 24GB)
      tok/                      (50 MB)
      eval_bundle/              (162 MB)
      identity_conversations.jsonl  (2.3 MB)

Repo root:
  .venv/                        (500-800 MB)
  rustbpe/target/               (1-2 GB)
  outs/
    base/                       (2.5 GB)
    mid/                        (2.5 GB)
    sft/                        (2.5 GB)
  report.md                     (100-500 KB)
```

**Total**: ~30-50 GB

---

### kat_speedrun.sh creates EVERYTHING above PLUS:

```
Home directory:
  .cache/
    nanochat/
      (all speedrun.sh files)
    data/                       (600 MB)
      pairs_all.jsonl           (500 MB)
      prompts_all.jsonl         (50 MB)
      prompt_id_map.tsv         (50 MB)
      stats.txt                 (1 KB)
    diversity_report.md         (50-100 KB)

Repo root:
  .venv/
  rustbpe/target/
  outs/
    base/                       (2.5 GB)
    mid/                        (2.5 GB)
    sft/                        (2.5 GB)
    rm/                         (100-200 MB)
    grpo_density/               (2.5 GB + 500 MB logs)
    grpo_baseline/              (2.5 GB + 500 MB logs)
  report.md
```

**Total**: ~35-55 GB

---

## SECTION 9: File Counts Summary

| Category        | Files    | Size           |
| --------------- | -------- | -------------- |
| Python venv     | ~50k     | 500-800 MB     |
| Rust build      | ~1k      | 1-2 GB         |
| Data shards     | 8-240    | 800 MB - 24 GB |
| Tokenizer       | 3        | 50 MB          |
| Eval bundle     | ~100+    | 162 MB         |
| Base checkpoint | 2-5      | 2.5 GB         |
| Mid checkpoint  | 2-5      | 2.5 GB         |
| SFT checkpoint  | 2-5      | 2.5 GB         |
| RM checkpoint   | 1-2      | 100-200 MB     |
| GRPO density    | 5-20     | 3 GB + logs    |
| GRPO baseline   | 5-20     | 3 GB + logs    |
| Reports         | 5-10     | 500 KB         |
| **Total**       | **~70k** | **35-55 GB**   |

---

## SECTION 10: What Can Be Deleted / Reused

### Safe to Delete (Can be redownloaded):

```
.cache/nanochat/data_shards/        # Can redownload
.cache/nanochat/eval_bundle/        # Can redownload (162 MB)
.cache/data/pairs_all.jsonl         # Can regenerate
.cache/data/prompts_all.jsonl       # Can regenerate from pairs
.cache/data/prompt_id_map.tsv       # Can regenerate from prompts
__pycache__/                         # Regenerated automatically
wandb/                               # wandb cache, safe to delete
```

### Keep (Required for continued work):

```
.venv/                               # Python env (needed for scripts)
rustbpe/target/                      # Compiled tokenizer
outs/sft/ckpt.pt                    # Base checkpoint (needed for GRPO)
outs/rm/ckpt.pt                     # RM checkpoint (needed for GRPO)
outs/grpo_density/ckpt.pt           # Main experiment model
outs/grpo_baseline/ckpt.pt          # Baseline model
.cache/diversity_report.md          # Results!
```

### Optional to Keep (For Debugging):

```
outs/*/logs/                        # TensorBoard logs
report.md                           # Training reports
outs/base/ckpt.pt                  # Can recreate if needed
outs/mid/ckpt.pt                   # Can recreate if needed
```

---

## SECTION 11: Quick Cleanup Commands

```bash
# Delete all data shards (keep space, can redownload)
rm -rf ~/.cache/nanochat/data_shards/

# Delete all eval bundles
rm -rf ~/.cache/nanochat/eval_bundle/

# Delete Python cache
find . -type d -name __pycache__ -exec rm -rf {} +
find . -name "*.pyc" -delete

# Delete TensorBoard logs (keeps space, loses metrics)
rm -rf outs/*/logs/

# Keep only essential files (~10 GB)
# Keep: .venv, rustbpe/target, outs/sft, outs/rm, outs/grpo_*
```

---

## SECTION 12: Storage Optimization

### Aggressive cleanup (safe):

```bash
# Delete: data shards, eval bundle, old checkpoints, logs
# Keep: .venv, final models
# Result: ~10-15 GB
```

### Medium cleanup (recommended):

```bash
# Keep: everything except logs and extra checkpoints
# Result: ~20-30 GB
```

### No cleanup (full):

```bash
# Keep: everything
# Result: ~35-55 GB
```

---

**Generated**: October 2025  
**For**: nanochat density-aware GRPO experiment
